# Tot Trecks : AI-Powered Baby Cry Monitor

An intelligent baby monitoring app that uses deep learning to detect an infant's cry in real-time, giving parents peace of mind via a live web dashboard and event logging.

---

## ğŸ§­ Problem â€” The Parent Anxiety Gap
Over **60%** of working parents report high anxiety about their babyâ€™s safety.  
Traditional monitors give audio/video but lack intelligence and actionable insights, leaving parents unsure, anxious, and sometimes unable to intervene during critical moments.

**Key pain points**
- No real-time visibility into babyâ€™s emotional/physical state.  
- Uncertainty about caregiver attentiveness.  
- No detection of critical events (seizures, abnormal stillness).  
- Delayed or no alerts for distressing behavior.  
- No centralized history/log for trend monitoring.

---

## âœ¨ Solution â€” Intelligent & Actionable Monitoring
This system bridges that gap by adding AI-powered detection and instant alerts on top of live audio/video.

**Core capabilities**
- ğŸ¯ Real-time cry detection (audio) using a Keras/TensorFlow model.  
- ğŸ›¡ï¸ Detection of abnormal movement / prolonged stillness (extendable).  
- ğŸ“² Instant notifications for critical events (WhatsApp, push, etc. â€” optional).  
- ğŸ“Š Live web dashboard showing current status + live feed.  
- ğŸ—„ï¸ Local event logging (SQLite) for history and trend review.

---

## ğŸš€ Features
- **Real-Time Audio Processing** â€” continuous microphone analysis.  
- **Deep Learning Model** â€” `baby_cry_model.h5` (Keras/TensorFlow).  
- **Web Dashboard** â€” Flask + HTML/CSS/JS for live updates.  
- **Event Logging** â€” SQLite (`baby_monitor.db`) with timestamps.  
- **Lightweight & Extensible** â€” modular design to add video analysis, notifications, caregiver accountability features.

---

## ğŸ› ï¸ Tech Stack
- **Backend:** Python, Flask  
- **ML:** TensorFlow, Keras, Librosa  
- **Audio:** PyAudio  
- **Database:** SQLite  
- **Frontend:** HTML, CSS, JavaScript  

---

## âš™ï¸ Setup & Installation

> **Prerequisites**
> - Python 3.8+  
> - `pip`  
> - `portaudio` (required for PyAudio)  
>
> macOS:  
> ```bash
> brew install portaudio
> ```
> Debian/Ubuntu:  
> ```bash
> sudo apt-get install portaudio19-dev
> ```

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/Spandan-Chakraborty/AI-Baby-Monitor.git
cd AI-Baby-Monitor
```
> Replace the repo URL if different.

### 2ï¸âƒ£ Create & activate a virtual environment
```bash
python -m venv venv
# macOS / Linux
source venv/bin/activate
# Windows (PowerShell)
venv\Scripts\Activate.ps1
# Windows (cmd)
venv\Scripts\activate
```

### 3ï¸âƒ£ Install dependencies
Create `requirements.txt` with:
```
Flask
tensorflow
numpy
librosa
pyaudio
```
Then run:
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Run the application
```bash
python app.py
```
Open `http://127.0.0.1:5000` in your browser to view the dashboard.

---

## ğŸ“– How to Use
1. Connect and enable a microphone on the machine running the server.  
2. Launch `app.py`.  
3. Open the dashboard URL in your browser.  
4. The app listens continuously â€” status updates between **Calm** and **Crying**.  
5. Cry events are recorded in `baby_monitor.db` with timestamps.

---

## ğŸ“‚ Project Structure
```
.
â”œâ”€â”€ app.py                  # Main Flask application logic
â”œâ”€â”€ baby_cry_model.h5       # Pre-trained Keras model for cry detection
â”œâ”€â”€ baby_monitor.db         # SQLite DB for event logging (auto-created)
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ dashboard.html      # Frontend HTML for the dashboard
â”œâ”€â”€ static/
â”‚   â””â”€â”€ style.css           # CSS for styling the dashboard
â”œâ”€â”€ README.md               # This file
â””â”€â”€ requirements.txt        # Python dependencies
```

---

## ğŸ”§ Extending the Project
- ğŸ“¹ Add video-based movement / seizure detection.  
- ğŸ“© Integrate WhatsApp / push notifications for critical events.  
- ğŸ” Add user auth + multi-device monitoring.  
- â˜ï¸ Cloud storage for long-term analytics and trend dashboards.  
- ğŸ“± Mobile app for push alerts and live viewing.

---

## ğŸ¤ Contributing
Contributions welcome!  
1. Fork the repo.  
2. Create a feature branch:  
   ```bash
   git checkout -b feature/your-feature
   ```
3. Commit changes & push.  
4. Open a Pull Request describing your changes.

Please open issues for bugs or feature requests.

---

## ğŸ“„ License
This project is released under the **MIT License**. See the `LICENSE` file for details.

---

## âš¡ Credits
Created by **Spandan Chakraborty**.
